{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic RNN - Extension of Static RNN\n",
    "#### Notebook Author: Nirupam Purushothama\n",
    "\n",
    "**About:** Dynamic unrolling through time\n",
    "* Uses while_loop() to run over the cell approprite number of times\n",
    "* Can swap GPU memory to CPU memory \n",
    "* Accepts a single tensor for all inputs at every timestep \n",
    "* Outputs a single tensor for all outputs at every timestep\n",
    "* No need to stack/unstack/transpose\n",
    "\n",
    "**Reference Book:** Hands-on Machine Learning with Scikit-Learn and TensorFlow - Aurelien Geron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3 # Number of inputs per mini-batch\n",
    "n_steps = 2 # Number of time steps\n",
    "n_neurons = 5 # Number of neurons\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch: instance 0, instance 1, instance 2, instance 3\n",
    "X_batch = np.array([\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]],\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]],    \n",
    "])\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.17320856 -0.81279624 -0.85754395  0.62516659 -0.24488541]\n",
      "  [-0.56728691 -0.99894196 -1.         -0.8792392   0.9999966 ]]\n",
      "\n",
      " [[-0.32289252 -0.9949863  -0.99992627  0.6759342   0.93173778]\n",
      "  [ 0.12957698  0.26272017 -0.85935092 -0.80255032  0.82559961]]\n",
      "\n",
      " [[-0.45799682 -0.99987763 -1.          0.72100621  0.99848628]\n",
      "  [ 0.04570349 -0.98267627 -0.99999964 -0.93722802  0.99994427]]\n",
      "\n",
      " [[ 0.98467076  0.96808958 -0.99687892 -0.93579489  0.99946827]\n",
      "  [-0.31260675 -0.80486101 -0.99101067 -0.10424052  0.99520844]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlike StaticRNN, here a while_loop goes over the time steps and stores the tensor values for each iteration during the forward pass so that it can use them to compute the gradients during the reverse pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
